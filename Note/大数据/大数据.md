# 1. 大数据的概述
## 1.1 大数据时代
第三次信息化浪潮（每隔15年一次）
- 数据存储能力提升
- cpu处理能力
- 网络带宽提升
- 数据产生方式

上述四种技术迎来了大数据阶段

## 1.2 大数据概念和影响
特性：4V
- 数据量大
- 数据类型多（结构化和非结构化）
- 处理速度快（秒）
- 价值密度低

影响：
通过数据驱动去发现问题（以前是发现有问题然后去解决，现在是通过数据驱动你发现新的问题）

## 1.3 大数据的应用
## 1.4 大数据关键技术
核心技术：
- 存储管理：分布式存储
- 处理分析：分布式处理

四种计算模式：批处理，流计算，图处理，查询分析，分别解决不同的问题
## 1.5 大数据与云计算，物联网
大数据继承自云计算

# 2. 大数据处理框架Hadoop
## 2.1.1 Hadhoop简介
Hadhoop有两个核心技术：分布式文件系统HDFS和分布式并行框架MapReduce（由Java开发）
- HDFS：实现海量数据的分布式存储
- MapReaduce：海量数据的分布式并行处理

良好的特性：
- 可靠性
- 高效性
- 可拓展性
- 成本低（把垃圾主机组成Hadoop构成集群）

![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191017155651.png)
## 2.1.2 Hadoop不同版本
- Hadoop1.0：
- Hadoop2.0：
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191017160100.png)

yarn可以支持很多计算框架：mapreduce，storm，spark

将开源Hadoop然后自己修改后发布：cloudera。。。。
## 2.2 Hadoop项目结构
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191017160748.png)
- HDFS:分布式文件存储系统（怎么用成百上千的服务器来分布式存储海量数据）
-  YARN框架：HDFS解决了文件存储，接下来需要处理数据，但是需要YARN来调度内存，cpu，带宽等计算资源
-  mapreduce：离线批处理
-  Tez：将你的mapreduce计算构建成有向无环图，保证最好的处理效率，相当于流程（让哪些工作先做，哪些后做，那些不要重复做）
-  spark：基于内存计算（mapreduce基于磁盘）
-  Hive：实现hadoop的数据仓库，实现更多数据存储，支持sql语句（由于hive在mapreduce之上，写的sql都要被转化成mapreduce作业）
-  Pig：实现流式数据处理，提供了类似sql查询语句pig latin，可以嵌套在别的开发语言中发布。（mapreduce编程很复杂，所以用pig）
-  Oozie：作业流调度系统，需要不同的系统相互配合完成，Oozie负责调度
-  zookeeper：分布式协调服务，管理集群的机器和分布式一致性
-  Hbase数据库：随机读写，支持实时应用
-  flume：专门日志收集，流数据实时收集用于实时分析
-  sqoop：帮我们将关系型数据库导入到hadoop平台上分析（可以导入到HDFS,habse,hive,反过来也可以导入到关系数据库）
-  ambari：安装部署的工具
## 2.3 Hadoop安装与使用
### 2.3.1 安装预备知识
### 2.3.2 安装Hadoop
[Hadoop安装教程](http://dblab.xmu.edu.cn/blog/install-hadoop/)
## 2.4 Hadoop集群部署和使用
- HDFS：
- - NameNode：应用首先访问这个节点，这个节点保存着应用所需要的数据存在哪些DataNode中（分布式存储）
- - DataNode：分布式存储中用来存储数据的节点
- - SecondaryNameNode：在Hadoop2.0中是NameNode中的热备份（主机出问题备用机立马顶上去），但是在1.0中是冷备份（主机出问题备用机等一会才能顶上去）
- mapreduce：
- - JobTracker：相当于作业管家，使用mapreduce开发时，每次是以一个mapreduce作业来完成计算任务，而JobTracker负责对这个作业进行管理（将一个大的计算任务拆分成若干小的计算任务，然后分发到各个小机器的TaskTracker上进行计算）
- - TaskTracker：负责跟踪和执行分配给自己的小作业。

首先，了解了Hadoop的几大核心组件之后，我们才能更好的部署集群（集群的硬件设施就是为了满足上面几个组件的需要）。在整个集群当中，大部分机器都是用来做数据节点DataNode和TaskTracker的，因为要存储海量数据和运行很多小的计算，而且这两个节点（DataNode和TaskTracker）可以部署在一台机器上。所以企业选机器的时候首先
- 磁盘要很大：一个机器挂在四个1~2T磁盘，而且支持JBOD磁盘簇
- cpu：要两颗4核心主频2.4g以上
- 内存16G以上
- 千兆以太网完成数据传输

NameNode（总管家）：
要管理各种元数据并提供服务，将文件映射表保存到内存中
- 内存：双通道以上32G到72G
- 磁盘：8到16个T
- cpu：两个四核或者八核处理器
- 千兆或者万兆以太网

集群较小（几台几十台）的时候，SecondaryNameNode可以放到NameNode机器上，较大（几千几百台）时，则需要另外配一台和NameNode一样的机器

首先买来机架，每个机架里面塞几十个刀片主机，一个机架内部的主机通过机架内部的交换机交换数据，机架与机架之间通过带宽更高的交换机连接，这样组成集群。

然后购买硬件，安装Hadoop，企业自动安装，甚至不用手动安装

但是企业基本都不会自己购买硬件安装服务器集群，都是通过购买网上阿里云来当服务器集群
# 3. 分布式文件系统
## 3.1 HDFS分布式文件系统简介
HDFS:Hadoop File System
首先买来机架，每个机架里面塞几十个刀片主机，一个机架内部的主机通过机架内部的交换机交换数据，机架与机架之间通过带宽更高的交换机连接，这样组成集群。
- HDFS设计目标：
 - - 兼容廉价的硬件设备
 - - 实现流数据读写：
 - - 支持大的文件：
 - - 支持简单的文件模型
 - - 强大的跨平台（Java）

- HDFS局限性：
- - 不适合低延时数据访问，实时性不高，不能满足实时处理<sup>?</sup>
- - 无法高效存储海量小文件（因为Hadoop中的NameNode需要对文件在内存中建立文件索引表，告诉你文件在哪个DataNode中，如果小文件过多，内存中的索引也会过多）
- - 不支持多用户写入及任意修改文件，只允许追加

## 3.2 HDFS相关概念
1. 块（HDFS中最核心的概念）：和普通的主机一样，为了降低寻址开销，但是HDFS却比普通的主机的"块"大很多，默认64M，这样是为了支持面向大规模数据存储和降低分布式节点的寻址开销

块设计的好处：
- 支持大规模文件存储（将大文件切割成块）
- 简化系统设计
- 适合数据备份 

2. 名称节点（NameNode）和数据节点（DataNode）

NameNode名称节点是整个HDFS的管家，相当于数据目录，数据节点负责实际存储数据

NameNode名称节点存储元数据：
- 文件是什么
- 文件分为多少块
- 每块的映射顺序
- 每块存储在哪个服务器上

NameNode名称节点的数据结构：
> FsImage：保存系统文件树以及所有文件文件夹的元数据（简单理解为目录树，但是不保存块在哪个数据节点存储的，此信息是内存有个单独区域来维护，不由FsImage维护）
> - 文件的复制等级
> - 修改和访问时间
> - 访问权限
> - 块大小以及组成文件的块

> EditLog：整个系统运行中记录对数据进行了哪些操作

那么HDFS系统是怎么将这两大模块结合使用的？（HDFS是怎么运作的）
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018091040.png)

首先shell命令启动Hadoop，然后Hadoop自动从磁盘中将FsImage加载到内存中来，然后EditLog中的各项操作进行合并得到最新的元数据FsImage，同时创建一个新的EditLog，旧版本就不要了，在系统运行的过程中FsImage基本不变化，只有EditLog变化

为什么要用到FsImage和EditLog？为什么不是用一个FsImage？

因为FsImage保存了海量的元数据，如果每次修改数据都要去修改FsImage的话，会导致性能下降，所以引入EditLog，EditLog非常小，操作性能高，但是随着系统运行，EditLog会不断增大，也会使得性能下降，这是需要引入第二名称节点SecondaryNameNode，第二名称节点会定期通过Http get方法从名称节点那里取走FsImage和EditLog并存放到本地，并将而这合并成一个新的FsImage，此时第一名称节点则生成一个edits.new来暂时放入在这期间的新的修改，并且在第二名称节点搬运FsImage和EditLog时停止使用二者。当第二名称节点利用第一名称节点的FsImage和EditLog完成生成新的FsImage时，就将新的FsImage发送到第一名称节点，然后第一名称节点把edits.new改为EditLog，这样既实现了第二名称节点的冷备份效果，还实现了在EditLog不断增大的情况下，FsImage和EditLog的合并，提高系统的使用效率。

## 3.3 HDFS体系结构
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018093543.png)

由上图可以看出，无论应用程序对数据进行读或者写，都需要先访问名称节点（主节点），知道数据分别存储在哪些机器里面，然后才可以找到数据进行操作

局限性：
- 命名空间（就是文件的绝对路径）的限制：因为所有的文件的元数据存储在内存中，那么就会有文件块个数的大小限制
- 性能瓶颈：整个HDFS系统的吞吐量，受限于单个名称节点的吞吐量，因为大家都要访问文件之前访问名称节点
- 隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此，无法对不同应用程序进行隔离
- 集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用。（第二名称节点（HDFS1.0）是冷备份，不能直接顶上去） 

## 3.5 HDFS存储原理 
HDFS存储原理：
- 冗余数据保存 
- 数据存取策略 
- 数据错误与恢复 

### 3.5.1 冗余数据保存
进行多个副本的备份
优点：
（1）加快数据传输速度（多个应用可以同时访问多个相同的副本）     （2）容易检查数据错误     （3）保证数据可靠性
### 3.5.2 数据存放
- 第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘 不太满、CPU不太忙的节点
- 第二个副本：放置在与第一个副本不同的机架的节点上
- 第三个副本：与第一个副本相同机架的其他节点上
- 更多副本：随机节点


![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018095233.png)
### 3.5.3数据读取
离客户端越近越好
- HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API 获取自己所属的机架ID
- 当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包 含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID， 当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副 本读取数据，如果没有发现，就随机选择一个副本读取数据 
### 3.5.4 数据错误与恢复
有三种错误情况：
1. 名称节点出错
2. 数据节点出错
3. 数据本身出错
#### 3.5.4.1 名称节点出错
（HDFS1.0）名称节点保存了所有的元数据信息，其中，最核心的两大数据结构是FsImage 和Editlog，如果这两个文件发生损坏，那么整个HDFS实例将失效。因此，HDFS设 置了备份机制，把这些核心文件同步复制到备份服务器SecondaryNameNode上。当 名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和 Editlog数据进行恢复
#### 3.5.4.2 数据节点出错
每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态，当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节 点的心跳信息，这时，这些数据节点就会被标记为“宕机”，节点上面的所有数据都 会被标记为“不可读”，名称节点不会再给它们发送任何I/O请求，这时，有可能出现一种情形，即由于一些数据节点的不可用，会导致一些数据块的 副本数量小于冗余因子，名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就 会启动数据冗余复制，为它生成新的副本，HDFS和其它分布式文件系统的最大区别就是可以调整冗余数据的位置
#### 3.5.4.3 数据出错
•网络传输和磁盘错误等因素，都会造成数据错误 •客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确 的数据 •在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到 同一个路径的隐藏文件里面 •当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读 取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文 件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这 个块 
## 3.6 HDFS数据读写过程 
### 3.6.1 HDFS数据读过程 
```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

import java.io.BufferedReader;
import java.io.InputStreamReader;


public class Chapter3 {
    public static void main(String[] args) {
        try {
            Configuration conf = new Configuration(); // 默认加载工程项目下的两个配置文件hdfs-site.xml和core-site.xml              
            FileSystem fs = FileSystem.get(conf);
            Path filename = new Path(
                    "hdfs://localhost:9000/user/hadoop/test.txt");
            FSDataInputStream is = fs.open(filename);// 打开文件，将文件写入到输入流再转化为二进制才能读取
            BufferedReader d = new BufferedReader(new InputStreamReader(is));
            String content = d.readLine(); // 读取文件一行 
            System.out.println(content);
            d.close(); // 关闭文件 
            fs.close(); // 关闭 hdfs 
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}

```
> 备注：创建一个Configuration对象时，其构造方法会默认加载工程项目下两个配置文件，分别是 hdfs-site.xml以及core-site.xml，这两个文件中会有访问HDFS所需的参数值，主要是 fs.defaultFS，指定了HDFS的地址（比如hdfs://localhost:9000），有了这个地址客户端就可以 通过这个地址访问HDFS了  
•FileSystem是一个通用文件系统的抽象基类，可以被分布式文件系统继承，所有可能使用 Hadoop文件系统的代码，都要使用这个类

 •Hadoop为FileSystem这个抽象类提供了多种具体实现 
 
 •DistributedFileSystem就是FileSystem在HDFS文件系统中的具体实现 
 
 •FileSystem的open()方法返回的是一个输入流FSDataInputStream对象，在HDFS文件系统中 ，具体的输入流就是DFSInputStream；FileSystem中的create()方法返回的是一个输出流 FSDataOutputStream对象，在HDFS文件系统中，具体的输出流就是DFSOutputStream。 
 ![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018103835.png)

 ### 3.6.2 HDFS数据写过程
 ![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018104617.png)

 ## 3.6 HDFS编程实践
 1. shell
 2. Java api

Hadoop中有三种Shell命令方式： （只要是带有dfs的，全部只适用于HDFS文件系统）
- hadoop fs（Hadoop FileSystem）适用于任何不同的文件系统，比如本地文件系统和HDFS文件系统 
- hadoop dfs（Hadoop DistributedFileSystem）：只能适用于HDFS文件系统 
- hdfs dfs：跟hadoop dfs的命令作用一样，也只能适用于HDFS文件系统

### 3.6.1 HDFS常用命令
- hadoop fs -ls path:显示path指定的文件的详细信息 
 
- hadoop fs -mkdir path:创建path指定的文件夹 

- hadoop fs -cat path:将path指定的文件的内容输出到标准输出（stdout）

- hadoop fs -copyFromLocal localsrc dst:将本地源文件localsrc复制到路径 dst指定的文件或文件夹中 (虽然我们的文件都是存储在自己的电脑磁盘中，但是我们电脑有两个文件系统，所以需要我们使用这个copy命令将本地文件上传到HDFS文件系统中去) 

### 3.6.2 Java api与HDFS交互  

# 4 分布式数据库Hbase
### 4.1.1 Hbase简介
Hbase前身是Google的BigTable分布式存储系统，解决互联网搜索问题，该系统利用Google提出的MapReduce进行计算，使用GFS作为底层数据存储，Hbase是BigTable的开源实现

![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018144721.png)
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018144700.png)

### 4.1.2关系数据库已经流行很多年，并且Hadoop已经有了HDFS和MapReduce，为什么需 要HBase? 
- Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于Hadoop MapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时 处理应用的需求
- HDFS面向批量访问模式，不是随机访问模式
- 传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题 （分库分表也不能很好解决）
- 传统关系数据库在数据结构变化时一般需要停机维护；空列浪费存储空间
- 因此，业界出现了一类面向半结构化数据存储和处理的高可扩展、低写入/查询延迟 的系统，例如，键值数据库、文档数据库和列族数据库（如BigTable和HBase等）
- HBase已经成功应用于互联网服务领域和传统行业的众多在线式数据分析处理系统中 

### 4.1.3 HBase与传统关系数据库的对比分析 
- 数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式， HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串 
- 数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。 HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、 清空等，因为HBase在设计上就避免了复杂的表和表之间的关系
- 存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个 列族都由几个文件保存，不同列族的文件是分离的 
- ）数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数 据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访 问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来 
- 数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来 的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数 据旧的版本，而是生成一个新的版本，旧有的版本仍然保留
- 可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相 反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的， 能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩
## 4.2 Hbase数据访问接口

![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018150033.png)
由以上方式访问Hbase数据库

## 4.3 Hbase数据模型
### 4.3.1 数据模型概述
- HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限 定符和时间戳 
- 每个值是一个未经解释的字符串，没有数据类型（数据类型的解释靠程序员自己）
- 用户在表中存储数据，每一行都有一个可排序的行键和任意多的列
- 表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一 个列族里面的数据存储在一起
- 列族支持动态扩展，可以很轻松地添加一个列族或列，无需预先定义列的数量以 及类型，所有列均以字符串形式存储，用户需要自行进行数据类型转换
- HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本， 旧有的版本仍然保留（这是和HDFS只允许追加不允许修改的特性相关的）

### 4.3.2 数据模型相关概念
- 表：HBase采用表来组织数据，表由行和列 组成，列划分为若干个列族 
- 行：每个HBase表都由若干行组成，每个行 由行键（row key）来标识。 
- 列族：一个HBase表被分组成许多“列族” （Column Family）的集合，它是基本的访 问控制单元 
- 列限定符：列族里的数据通过列限定符（或 列）来定位 
- 单元格：在HBase表中，通过行、列族和列 限定符确定一个“单元格”（cell），单元 格中存储的数据没有数据类型，总被视为字 节数组byte[] 
- 时间戳：每个单元格都保存着同一份数据的 多个版本，这些版本采用时间戳进行索引

### 4.3.3 数据坐标
HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一 个“四维坐标”，即[行键, 列族, 列限定符, 时间戳] 

![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018154939.png)

### 4.3.4 概念视图
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018155930.png)
从概念上是稀疏表

### 4.3.5 物理视图
![](https://raw.githubusercontent.com/Raymond0225/picbed/master/img/20191018160318.png)
将各个列族，时间戳分别提取处理，然后进行组合，如上图所示，解决了稀疏表的问题
### 4.3.6 面向列的存储
传统数据库采用行存储，将新的数据一行插入到数据库中，但是不利于分析，因为我们分析往往只是分析某一列的数据（如年龄，性别），所以采用面向列存储，效率较高，且按列存储数据类型都是一样的，便于数据压缩，面向行则不行
## 4.4 Hbase实现原理
### 4.4.1 HBase功能组件
- 库函数：链接到每个客户端（客户端利用库函数可以访问Hbase服务器） 
- 一个Master主服务器（管家） 
- 许多个Region服务器 

• 主服务器Master负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡

• Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求 

• 客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信 息后，直接从Region服务器上读取数据 

• 客户端并不依赖Master，而是通过Zookeeper来获得Region位置信息，大多数客户 端甚至从来不和Master通信，这种设计方式使得Master负载很小

